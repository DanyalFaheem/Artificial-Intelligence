{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45bbe70d",
   "metadata": {},
   "source": [
    "# Lab 14 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35b95d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41cb4af",
   "metadata": {},
   "source": [
    "###  Task :: Make a Neural Network from scratch. It will be a two layer Neural network. You have to perform feedforward to calcluate the output. Along with this we will have to perform backpropagation to update the wights according to the loss.The following steps will be guidelines that will help you along the way. \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d544c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for iteration # 0\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.86471804]\n",
      " [0.90085259]\n",
      " [0.90337686]\n",
      " [0.9228109 ]]\n",
      "Loss:  \n",
      "0.4046208733449593\n",
      "\n",
      "\n",
      "for iteration # 100\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.80930545 0.80966506 0.80970319 0.80967539]\n",
      " [0.84773186 0.84752616 0.84765755 0.84754085]\n",
      " [0.85282294 0.85287157 0.85271223 0.85285089]\n",
      " [0.87452418 0.87421991 0.87420529 0.87421346]]\n",
      "Loss:  \n",
      "0.36617522811652486\n",
      "\n",
      "\n",
      "for iteration # 200\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.71333186 0.72619776 0.72755136 0.72656201]\n",
      " [0.74773315 0.7608527  0.76244233 0.76125156]\n",
      " [0.75434094 0.76771883 0.76888566 0.76806419]\n",
      " [0.77513723 0.78847035 0.78988802 0.78884817]]\n",
      "Loss:  \n",
      "0.3136207517650549\n",
      "\n",
      "\n",
      "for iteration # 300\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.4438971  0.44445598 0.44416422 0.44449397]\n",
      " [0.4379336  0.43754569 0.43772691 0.43758046]\n",
      " [0.44414511 0.44443219 0.44429707 0.44438743]\n",
      " [0.43748011 0.43695593 0.43722202 0.43693077]]\n",
      "Loss:  \n",
      "0.25335718843491256\n",
      "\n",
      "\n",
      "for iteration # 400\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.12777395 0.12808557 0.12792442 0.12810563]\n",
      " [0.09562231 0.09554025 0.09557708 0.0955551 ]\n",
      " [0.09629146 0.09644811 0.09637301 0.09643502]\n",
      " [0.07715733 0.07705586 0.07710799 0.07705104]]\n",
      "Loss:  \n",
      "0.4142059734529048\n",
      "\n",
      "\n",
      "for iteration # 500\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.13557777 0.12375299 0.12950013 0.12304426]\n",
      " [0.10328458 0.09203971 0.09747193 0.09139352]\n",
      " [0.10493279 0.09364298 0.09910578 0.09295223]\n",
      " [0.08499859 0.07450407 0.07955635 0.07389041]]\n",
      "Loss:  \n",
      "0.41348490085148215\n",
      "\n",
      "\n",
      "for iteration # 600\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.78421638 0.78394292 0.78379097 0.78397156]\n",
      " [0.8224648  0.82213091 0.82229658 0.82214377]\n",
      " [0.83069051 0.83130561 0.83128941 0.83126268]\n",
      " [0.85195096 0.85222262 0.85242176 0.85219058]]\n",
      "Loss:  \n",
      "0.350242723423917\n",
      "\n",
      "\n",
      "for iteration # 700\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.59055784 0.59047257 0.59041252 0.59048239]\n",
      " [0.60886672 0.60867704 0.60912858 0.60866195]\n",
      " [0.62084929 0.62223507 0.62238953 0.62212705]\n",
      " [0.63023446 0.63112553 0.63169237 0.63102683]]\n",
      "Loss:  \n",
      "0.2607063685361835\n",
      "\n",
      "\n",
      "for iteration # 800\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.66365071 0.66315246 0.66286546 0.66320581]\n",
      " [0.69193328 0.69129073 0.69143446 0.69132712]\n",
      " [0.70470823 0.70546699 0.70534653 0.70542068]\n",
      " [0.72037807 0.72064876 0.72086347 0.72061613]]\n",
      "Loss:  \n",
      "0.28530560658819226\n",
      "\n",
      "\n",
      "for iteration # 900\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.72331069 0.72289839 0.72266457 0.72294239]\n",
      " [0.75825727 0.75774122 0.75788995 0.75776843]\n",
      " [0.77183067 0.7725076  0.77242979 0.77246451]\n",
      " [0.79077841 0.79103694 0.79123817 0.79100609]]\n",
      "Loss:  \n",
      "0.31470409585587855\n",
      "\n",
      "\n",
      "for iteration # 1000\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.84122468 0.84089077 0.84070538 0.84092616]\n",
      " [0.87873473 0.87837939 0.87843851 0.87840088]\n",
      " [0.88897203 0.88929981 0.8892307  0.88928094]\n",
      " [0.90721976 0.90730263 0.9073809  0.90729191]]\n",
      "Loss:  \n",
      "0.3893521065748974\n",
      "\n",
      "\n",
      "for iteration # 1100\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.84178305 0.84547364 0.84709501 0.84511678]\n",
      " [0.87982247 0.88322309 0.88495128 0.88287976]\n",
      " [0.89167887 0.89544656 0.89691587 0.89509433]\n",
      " [0.9095003  0.91282865 0.91434223 0.91250423]]\n",
      "Loss:  \n",
      "0.3927299129198758\n",
      "\n",
      "\n",
      "for iteration # 1200\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.85442343 0.85411651 0.85395625 0.85414842]\n",
      " [0.89317124 0.89285626 0.89291986 0.89287462]\n",
      " [0.90658126 0.90686627 0.90681689 0.9068492 ]\n",
      " [0.92331345 0.9233862  0.92346088 0.92337643]]\n",
      "Loss:  \n",
      "0.400594645713801\n",
      "\n",
      "\n",
      "for iteration # 1300\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.86254934 0.86252077 0.86249572 0.86252435]\n",
      " [0.90080234 0.90074167 0.90091405 0.90073506]\n",
      " [0.91522417 0.9156896  0.91574311 0.91565327]\n",
      " [0.93086117 0.9311151  0.93127329 0.93108719]]\n",
      "Loss:  \n",
      "0.40695777661623844\n",
      "\n",
      "\n",
      "for iteration # 1400\n",
      "\n",
      "Input : \n",
      "[[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 1.]\n",
      " [1. 1. 1.]]\n",
      "Actual Output:  \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Predicted Output : \n",
      " [[0.62391903 0.62344329 0.62316951 0.62349427]\n",
      " [0.65805997 0.65743268 0.65761349 0.6574657 ]\n",
      " [0.70003989 0.70085349 0.70075989 0.70080168]\n",
      " [0.71121327 0.71153955 0.71178736 0.71150098]]\n",
      "Loss:  \n",
      "0.27546200988624014\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1 : Make a neural network class that has attributes : input , weightsFirstLayer , weightsSecondLayer , provided output ,\n",
    "#         and calculated output(should be similar shape as provided output). The weights should be initialized at random.\n",
    "\n",
    "# --Help for Step 1--\n",
    "# Size of weights for first layer: As your input has an array of 3 features(cols) and their respective 4 rows.\n",
    "# Size of weights for second layer: As now your iput  is the result of first layer(four values) mutiplied with weights.\n",
    "\n",
    "# Step 2: Follow the algo written in feed forward\n",
    "\n",
    "# Step 3: Follow algo of bakpropogate (Here the lecture comes in handy)\n",
    "\n",
    "# Step 4: Run fun as is\n",
    "\n",
    "# Step 5: Ask me for runner code\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, x, y):\n",
    "        self.w1 = np.random.rand(3, 4)\n",
    "        self.w2 = np.random.rand(4, 1)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def sigmoid(self, t):\n",
    "        return 1 / (1 + np.exp(-t))\n",
    "\n",
    "    def sigmoid_derivative(self, p):\n",
    "        return p * (1 - p)\n",
    "\n",
    "    def feedforward(self):\n",
    "        FirstLayer = self.sigmoid(np.dot(self.x, self.w1))\n",
    "        SecLayer = self.sigmoid(np.dot(FirstLayer, self.w2))\n",
    "        return FirstLayer, SecLayer\n",
    "\n",
    "    def backpropogate(self, first, second):\n",
    "        # For last layer weights\n",
    "        # d1_w = a^(l-1)*Sig(a^(l))*2(out-a^(l))\n",
    "        d1_w = np.dot(np.transpose(np.squeeze(np.asarray(first))), np.dot(\n",
    "            self.sigmoid_derivative(np.squeeze( np.asarray(second))), 2 * (self.y - np.squeeze(np.asarray(second)))))\n",
    "        # For Sec last layer weights\n",
    "        # d2_w = a^(l-2)*Sig(a^(l))*2(out-a^(l))*W2*Sig(a^(l-1))\n",
    "        # d2_w = np.dot(\n",
    "        d2_w =  np.dot(np.transpose(self.x), \n",
    "        np.dot(self.sigmoid_derivative( \n",
    "            np.squeeze( np.asarray(second))),  \n",
    "        2 * (self.y - np.squeeze( np.asarray(second)))))\n",
    "        # np.dot(self.w1,  self.sigmoid_derivative(np.squeeze(np.asarray(first)))))\n",
    "        self.w2 = np.add(self.w2, d1_w)\n",
    "        temp = np.zeros(np.shape(self.w1))\n",
    "        #print(np.matrix(d2_w))\n",
    "        # self.w1 = np.add(self.w1, n)\n",
    "        # print(np.matrix(self.w1))\n",
    "        # print(np.matrix(d1_w))\n",
    "        # np.add(self.w2, d2_w)\n",
    "        # Add them to exisiting weights\n",
    "\n",
    "    def Train(self):\n",
    "        First, Second = self.feedforward()\n",
    "        self.backpropogate(First, Second)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # input = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=float)\n",
    "    # output = np.array([[0], [1], [1], [0]], dtype=float)\n",
    "    X = np.array([[0, 0, 1], [0, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=float)\n",
    "    y = np.array([[0], [1], [1], [0]], dtype=float)\n",
    "    NN = NeuralNetwork(X, y)\n",
    "    for i in range(1500):\n",
    "        if i % 100 == 0:\n",
    "            print(\"for iteration # \" + str(i) + \"\\n\")\n",
    "            print(\"Input : \\n\" + str(X))\n",
    "            print(\"Actual Output:  \\n\" + str(y))\n",
    "            First, Second = NN.feedforward()\n",
    "            print(\"Predicted Output : \\n\", np.matrix(Second))\n",
    "            print(\"Loss:  \\n\" + str(np.mean(np.square(y - Second))))\n",
    "            print(\"\\n\")\n",
    "        NN.Train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16742134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7fee64b6d10f71b2ad32d2aedca1959ec8ccaf90c3c6db5aa37e1a96c8621a02"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('DIP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
